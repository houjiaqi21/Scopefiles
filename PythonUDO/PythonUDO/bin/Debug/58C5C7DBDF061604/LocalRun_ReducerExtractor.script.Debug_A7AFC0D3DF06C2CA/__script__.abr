<?xml version="1.0" encoding="utf-8"?>
<ScriptAndGraph GraphType="VertexCommands">
  <Vertices count="2">
    <Vertex index="1" command="-scopeVertex SV1_Extract -i D:\Sharing\Scope2015\PythonUDO\PythonUDO\users\v-hozhao\All_In_One\Input\Python_iris.csv -o D:\Sharing\Scope2015\PythonUDO\PythonUDO\bin\Debug\58C5C7DBDF061604\_Temp\LocalRun_ReducerExtractor.script.Debug_A7AFC0D3DF06C2CA\scopetmpfile._SV1_Extract_out0" />
    <Vertex index="2" command="-scopeVertex SV2_Extract -i D:\Sharing\Scope2015\PythonUDO\PythonUDO\users\v-hozhao\All_In_One\Input\Python_SearchLog.tsv -o D:\Sharing\Scope2015\PythonUDO\PythonUDO\bin\Debug\58C5C7DBDF061604\_Temp\LocalRun_ReducerExtractor.script.Debug_A7AFC0D3DF06C2CA\scopetmpfile._SV2_Extract_out0" />
    <Vertex command="-concatenate -i D:\Sharing\Scope2015\PythonUDO\PythonUDO\bin\Debug\58C5C7DBDF061604\_Temp\LocalRun_ReducerExtractor.script.Debug_A7AFC0D3DF06C2CA\scopetmpfile._SV1_Extract_out0 -o D:\Sharing\Scope2015\PythonUDO\PythonUDO\users\v-hozhao\All_In_One\Output\Python_ClusterRun_DataFrame_Reducer_Demo_Output.txt" />
    <Vertex command="-concatenate -i D:\Sharing\Scope2015\PythonUDO\PythonUDO\bin\Debug\58C5C7DBDF061604\_Temp\LocalRun_ReducerExtractor.script.Debug_A7AFC0D3DF06C2CA\scopetmpfile._SV2_Extract_out0 -o D:\Sharing\Scope2015\PythonUDO\PythonUDO\users\v-hozhao\All_In_One\Output\Python_ClusterRun_Extractor_Demo_Output.txt" />
  </Vertices>
  <Outputs>
    <Output path="D:\Sharing\Scope2015\PythonUDO\PythonUDO\users\v-hozhao\All_In_One\Output\Python_ClusterRun_DataFrame_Reducer_Demo_Output.txt" isBinary="False" schema="SepalLength_Mean:double,SepalWidth_Mean:double,PetalLength_Mean:double,PetalWidth_Mean:double,Name:string,Count:int" />
    <Output path="D:\Sharing\Scope2015\PythonUDO\PythonUDO\users\v-hozhao\All_In_One\Output\Python_ClusterRun_Extractor_Demo_Output.txt" isBinary="False" schema="UserId:string,Start:string,Region:string,Query:string,Duration:string,Urls:string,ClickedUrls:string" />
  </Outputs>
  <graph JsonErrors="True" JobType="BatchScopeServerGC" vertexExecutable="scopehost.exe" BroadcastCopyThroughCommandLine="ScopeEngine.dll -scopeVertex SV_CopyThrough">
    <process id="SV1_Extract" command="ScopeEngine.dll -scopeVertex SV1_Extract" managedMemorySize="0" adapterMemorySize="1283457024" engineIOMemorySize="1698693456" engineOperatorMemorySize="4720347912" DummyVertexOptimization="AllInputsEmptyImpliesOutputsEmpty|RunAtLeastOneVertex">
      <input id="Extract_0[ALL]" streamSize="4698" cosmosStream="D:\Sharing\Scope2015\PythonUDO\PythonUDO\users\v-hozhao\All_In_One\Input\Python_iris.csv">
        <cosmosStream cosmosPath="D:\Sharing\Scope2015\PythonUDO\PythonUDO\users\v-hozhao\All_In_One\Input\Python_iris.csv" streamSize="4698" />
      </input>
      <output id="SV1_Extract_out0" cosmosStream="D:\Sharing\Scope2015\PythonUDO\PythonUDO\users\v-hozhao\All_In_One\Output\Python_ClusterRun_DataFrame_Reducer_Demo_Output.txt" />
    </process>
    <process id="SV2_Extract" command="ScopeEngine.dll -scopeVertex SV2_Extract" managedMemorySize="0" adapterMemorySize="1283457024" engineIOMemorySize="1581253280" engineOperatorMemorySize="262144112" DummyVertexOptimization="AllInputsEmptyImpliesOutputsEmpty|RunAtLeastOneVertex">
      <input id="Extract_4[ALL]" streamSize="3183" cosmosStream="D:\Sharing\Scope2015\PythonUDO\PythonUDO\users\v-hozhao\All_In_One\Input\Python_SearchLog.tsv">
        <cosmosStream cosmosPath="D:\Sharing\Scope2015\PythonUDO\PythonUDO\users\v-hozhao\All_In_One\Input\Python_SearchLog.tsv" streamSize="3183" />
      </input>
      <output id="SV2_Extract_out0" cosmosStream="D:\Sharing\Scope2015\PythonUDO\PythonUDO\users\v-hozhao\All_In_One\Output\Python_ClusterRun_Extractor_Demo_Output.txt" />
    </process>
  </graph>
  <Scopescript>#DECLARE import_codebehind_LocalRun_ReducerExtractor1_py string = @"'''
  The following is a sample Python UDO.
  Details on Python UDOs: https://microsoft.sharepoint.com/:w:/r/teams/Cosmos/_layouts/15/Doc.aspx?sourcedoc=%7B7E714159-3C83-4822-A357-B44503EF0C80%7D&amp;file=Scope_Python%20UDO%20Extenstion.docx&amp;action=default&amp;mobileredirect=true&amp;DefaultItemOpen=1&amp;cid=e5947e3b-6d54-429b-a1bf-eb226be1a3cf
'''

class DataFrameDemoReducer:
    def __init__(self):
        self.pyadlahelper = __import__('pyadlahelper')
        pass

    def Reduce(self, inputRowset, outputRow):
        df = self.pyadlahelper.RowsetToDataframe(inputRowset, -1)
        outputRow['Name'] = inputRowset.Key['Name']
        outputRow['Count'] = len(df)
        distribution = df.describe()
        outputRow['SepalLength_Mean'] = round(distribution['SepalLength']['mean'], 2)
        outputRow['SepalWidth_Mean'] = round(distribution['SepalWidth']['mean'], 2)
        outputRow['PetalLength_Mean'] = round(distribution['PetalLength']['mean'], 2)
        outputRow['PetalWidth_Mean'] = round(distribution['PetalWidth']['mean'], 2)
        yield outputRow

class SearchLogExtractor:
    def __init__(self):
        pass

    def Extract(self, rawInput, outputRow):
        stream = rawInput.GetBaseStream
        bufferToRead = bytearray(100 * 1024 * 1024)
        numBytesRead = stream.readinto(bufferToRead)
        if numBytesRead == len(bufferToRead):
            raise RuntimeError('input stream is too big')

        for row in bufferToRead[:numBytesRead].decode('utf-8').split('\r\n'):
            for columnIndex, columnValue in enumerate(row.split('\t')):
                columnType = outputRow.Schema[columnIndex].Type
                outputRow[columnIndex] = columnType(columnValue)

            yield outputRow
";

REFERENCE @"c:\program files (x86)\microsoft visual studio\2019\enterprise\common7\ide\extensions\microsoft\scopestudio\2.9.0000.1\ScopeStudioDebugRuntime.dll";
//Script GUID:b5026507-d182-4878-930e-897fdb739d7a
//Used for tracking history


#DECLARE input_Reducer string = @"/users/v-hozhao/All_In_One/Input/Python_iris.csv";
#DECLARE output_Reducer string = @"/users/v-hozhao/All_In_One/Output/Python_ClusterRun_DataFrame_Reducer_Demo_Output.txt";

Input =
    EXTRACT SepalLength: double,
            SepalWidth: double,
            PetalLength: double, 
            PetalWidth: double, 
            Name: string
    FROM @input_Reducer
    USING DefaultTextExtractor(delimiter:',');

Out =
    REDUCE Input ON Name
    PRODUCE SepalLength_Mean: double, 
            SepalWidth_Mean: double, 
            PetalLength_Mean: double, 
            PetalWidth_Mean: double, 
            Name: string,
            Count: int
    USING Reducers.Python(prologue: @import_codebehind_LocalRun_ReducerExtractor1_py, expression: "DataFrameDemoReducer()");

OUTPUT Out
TO @output_Reducer
USING DefaultTextOutputter(delimiter:',');

////////////////////////////////////////////////////////////

#DECLARE input_Extractor string = @"/users/v-hozhao/All_In_One/Input/Python_SearchLog.tsv";   //Input
#DECLARE output_Extractor string = @"/users/v-hozhao/All_In_One/Output/Python_ClusterRun_Extractor_Demo_Output.txt";  //Output

searchlog =
    EXTRACT UserId: string,
            Start: string,
            Region: string,
            Query: string,
            Duration: string,
            Urls: string,
            ClickedUrls: string
    FROM @input_Extractor
    USING Extractors.Python(prologue: @import_codebehind_LocalRun_ReducerExtractor1_py, expression: "SearchLogExtractor()");

OUTPUT searchlog
TO @output_Extractor
USING DefaultTextOutputter(delimiter:',');

// Generated by ScopeStudio, version 2.9.0000.1
</Scopescript>
  <Optimization succeeded="true" time="00:00:00.3264180" latency="0.0297163542407407" totalCost="0.0498679628289059" />
  <ScopeVertexAnnotations>
    <ScopeVertex name="SV1_Extract">
      <Operation annotation="REDUCE USING Python" />
    </ScopeVertex>
    <ScopeVertex name="SV2_Extract">
      <Operation annotation="EXTRACT USING Python" />
    </ScopeVertex>
  </ScopeVertexAnnotations>
</ScriptAndGraph>