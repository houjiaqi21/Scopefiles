#DECLARE import_codebehind_LocalRun_ReducerExtractor1_py string = @"'''
  The following is a sample Python UDO.
  Details on Python UDOs: https://microsoft.sharepoint.com/:w:/r/teams/Cosmos/_layouts/15/Doc.aspx?sourcedoc=%7B7E714159-3C83-4822-A357-B44503EF0C80%7D&file=Scope_Python%20UDO%20Extenstion.docx&action=default&mobileredirect=true&DefaultItemOpen=1&cid=e5947e3b-6d54-429b-a1bf-eb226be1a3cf
'''

class DataFrameDemoReducer:
    def __init__(self):
        self.pyadlahelper = __import__('pyadlahelper')
        pass

    def Reduce(self, inputRowset, outputRow):
        df = self.pyadlahelper.RowsetToDataframe(inputRowset, -1)
        outputRow['Name'] = inputRowset.Key['Name']
        outputRow['Count'] = len(df)
        distribution = df.describe()
        outputRow['SepalLength_Mean'] = round(distribution['SepalLength']['mean'], 2)
        outputRow['SepalWidth_Mean'] = round(distribution['SepalWidth']['mean'], 2)
        outputRow['PetalLength_Mean'] = round(distribution['PetalLength']['mean'], 2)
        outputRow['PetalWidth_Mean'] = round(distribution['PetalWidth']['mean'], 2)
        yield outputRow

class SearchLogExtractor:
    def __init__(self):
        pass

    def Extract(self, rawInput, outputRow):
        stream = rawInput.GetBaseStream
        bufferToRead = bytearray(100 * 1024 * 1024)
        numBytesRead = stream.readinto(bufferToRead)
        if numBytesRead == len(bufferToRead):
            raise RuntimeError('input stream is too big')

        for row in bufferToRead[:numBytesRead].decode('utf-8').split('\r\n'):
            for columnIndex, columnValue in enumerate(row.split('\t')):
                columnType = outputRow.Schema[columnIndex].Type
                outputRow[columnIndex] = columnType(columnValue)

            yield outputRow
";

REFERENCE @"C:\Program Files (x86)\Reference Assemblies\Microsoft\Framework\.NETFramework\v4.5\System.Core.dll";
//Script GUID:b5026507-d182-4878-930e-897fdb739d7a
//Used for tracking history


#DECLARE input_Reducer string = @"/users/v-hozhao/All_In_One/Input/Python_iris.csv";
#DECLARE output_Reducer string = @"/users/v-hozhao/All_In_One/Output/Python_ClusterRun_DataFrame_Reducer_Demo_Output.txt";

Input =
    EXTRACT SepalLength: double,
            SepalWidth: double,
            PetalLength: double, 
            PetalWidth: double, 
            Name: string
    FROM @input_Reducer
    USING DefaultTextExtractor(delimiter:',');

Out =
    REDUCE Input ON Name
    PRODUCE SepalLength_Mean: double, 
            SepalWidth_Mean: double, 
            PetalLength_Mean: double, 
            PetalWidth_Mean: double, 
            Name: string,
            Count: int
    USING Reducers.Python(prologue: @import_codebehind_LocalRun_ReducerExtractor1_py, expression: "DataFrameDemoReducer()");

OUTPUT Out
TO @output_Reducer
USING DefaultTextOutputter(delimiter:',');

////////////////////////////////////////////////////////////

#DECLARE input_Extractor string = @"/users/v-hozhao/All_In_One/Input/Python_SearchLog.tsv";   //Input
#DECLARE output_Extractor string = @"/users/v-hozhao/All_In_One/Output/Python_ClusterRun_Extractor_Demo_Output.txt";  //Output

searchlog =
    EXTRACT UserId: string,
            Start: string,
            Region: string,
            Query: string,
            Duration: string,
            Urls: string,
            ClickedUrls: string
    FROM @input_Extractor
    USING Extractors.Python(prologue: @import_codebehind_LocalRun_ReducerExtractor1_py, expression: "SearchLogExtractor()");

OUTPUT searchlog
TO @output_Extractor
USING DefaultTextOutputter(delimiter:',');

// Generated by ScopeStudio, version 2.9.0000.1
